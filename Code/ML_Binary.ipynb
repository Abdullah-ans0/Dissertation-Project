{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3951473c",
   "metadata": {},
   "source": [
    "# Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fa333b-ef99-4ccd-a9f7-f63b051d6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015bb7c",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86931adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for class_label, class_folder in enumerate(os.listdir(folder)):\n",
    "        class_path = os.path.join(folder, class_folder)\n",
    "        for filename in os.listdir(class_path):\n",
    "            img = cv2.imread(os.path.join(class_path, filename))\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  # Resize images\n",
    "                images.append(img)\n",
    "                labels.append(class_label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "data_folder = 'Binary_Data'\n",
    "images, labels = load_images_from_folder(data_folder)\n",
    "images = images / 255.0  # Normalize pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4540b7",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b720fc-840e-4ca7-84cb-90f607883165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for image in images:\n",
    "        gray_image = rgb2gray(image)\n",
    "        feature = hog(gray_image, pixels_per_cell=(8, 8), cells_per_block=(2, 2))\n",
    "        hog_features.append(feature)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "hog_features = extract_hog_features(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44824eb3",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89373db-444f-4aad-8548-3910f469f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hog_features, labels, test_size=0., random_state=1, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c468b",
   "metadata": {},
   "source": [
    "# Creating pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2ff6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('svm', SVC()) \n",
    "])\n",
    "\n",
    "# KNN Pipeline\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('knn', KNeighborsClassifier())  \n",
    "])\n",
    "\n",
    "# Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('rf', RandomForestClassifier()) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b8884",
   "metadata": {},
   "source": [
    "# Training and evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e91d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "SVM Model Accuracy: 80.86%\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1332\n",
      "           1       0.81      0.80      0.81      1322\n",
      "\n",
      "    accuracy                           0.81      2654\n",
      "   macro avg       0.81      0.81      0.81      2654\n",
      "weighted avg       0.81      0.81      0.81      2654\n",
      "\n",
      "\n",
      "Training KNN model...\n",
      "KNN Model Accuracy: 66.65%\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.96      0.74      1332\n",
      "           1       0.91      0.37      0.52      1322\n",
      "\n",
      "    accuracy                           0.67      2654\n",
      "   macro avg       0.76      0.67      0.63      2654\n",
      "weighted avg       0.76      0.67      0.63      2654\n",
      "\n",
      "\n",
      "Training Random Forest model...\n",
      "Random Forest Model Accuracy: 74.38%\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75      1332\n",
      "           1       0.75      0.73      0.74      1322\n",
      "\n",
      "    accuracy                           0.74      2654\n",
      "   macro avg       0.74      0.74      0.74      2654\n",
      "weighted avg       0.74      0.74      0.74      2654\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelines = [svm_pipeline, knn_pipeline, rf_pipeline]\n",
    "pipeline_names = ['SVM', 'KNN', 'Random Forest']\n",
    "\n",
    "for name, pipeline in zip(pipeline_names, pipelines):\n",
    "    print(f\"Training {name} model...\")\n",
    "    pipeline.fit(X_train, y_train)  \n",
    "    y_pred = pipeline.predict(X_test)  \n",
    "    accuracy = accuracy_score(y_test, y_pred)  \n",
    "    print(f\"{name} Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Classification Report for {name}:\\n{classification_report(y_test, y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de43f15",
   "metadata": {},
   "source": [
    "# Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9636ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving each trained pipeline to a file\n",
    "for name, pipeline in zip(pipeline_names, pipelines):\n",
    "    filename = f\"{name}_binary.pkl\" \n",
    "    joblib.dump(pipeline, filename)  \n",
    "    print(f\"{name} model saved as {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
